{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Multi-Domain Sentiment Dataset\n",
    "For More Details See: [Website](http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# D:\\Random ML Projects\\Simple Sentiment Analysis Logistic Model\\sorted_data_acl\\electronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'among',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'around',\n",
       " 'as',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'at',\n",
       " 'away',\n",
       " 'b',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'backing',\n",
       " 'backs',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'come',\n",
       " 'could',\n",
       " 'd',\n",
       " 'did',\n",
       " 'differ',\n",
       " 'different',\n",
       " 'differently',\n",
       " 'do',\n",
       " 'does',\n",
       " 'done',\n",
       " 'down',\n",
       " 'downed',\n",
       " 'downing',\n",
       " 'downs',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'early',\n",
       " 'either',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'evenly',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'f',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'far',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'first',\n",
       " 'for',\n",
       " 'four',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'further',\n",
       " 'furthered',\n",
       " 'furthering',\n",
       " 'furthers',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'goods',\n",
       " 'got',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'grouping',\n",
       " 'groups',\n",
       " 'h',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'herself',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'i',\n",
       " 'if',\n",
       " 'important',\n",
       " 'in',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interests',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kind',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'l',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'last',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'least',\n",
       " 'less',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'like',\n",
       " 'likely',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'longest',\n",
       " 'm',\n",
       " 'made',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'member',\n",
       " 'members',\n",
       " 'men',\n",
       " 'might',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needing',\n",
       " 'needs',\n",
       " 'never',\n",
       " 'new',\n",
       " 'newer',\n",
       " 'newest',\n",
       " 'next',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'noone',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'old',\n",
       " 'older',\n",
       " 'oldest',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'opening',\n",
       " 'opens',\n",
       " 'or',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'ordering',\n",
       " 'orders',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'p',\n",
       " 'part',\n",
       " 'parted',\n",
       " 'parting',\n",
       " 'parts',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'place',\n",
       " 'places',\n",
       " 'point',\n",
       " 'pointed',\n",
       " 'pointing',\n",
       " 'points',\n",
       " 'possible',\n",
       " 'present',\n",
       " 'presented',\n",
       " 'presenting',\n",
       " 'presents',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'put',\n",
       " 'puts',\n",
       " 'q',\n",
       " 'quite',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'really',\n",
       " 'right',\n",
       " 'room',\n",
       " 'rooms',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'says',\n",
       " 'second',\n",
       " 'seconds',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'sees',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showing',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'sides',\n",
       " 'since',\n",
       " 'small',\n",
       " 'smaller',\n",
       " 'smallest',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'somewhere',\n",
       " 'state',\n",
       " 'states',\n",
       " 'still',\n",
       " 'such',\n",
       " 'sure',\n",
       " 't',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinks',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'thoughts',\n",
       " 'three',\n",
       " 'through',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'turn',\n",
       " 'turned',\n",
       " 'turning',\n",
       " 'turns',\n",
       " 'two',\n",
       " 'u',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'uses',\n",
       " 'v',\n",
       " 'very',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wanting',\n",
       " 'wants',\n",
       " 'was',\n",
       " 'way',\n",
       " 'ways',\n",
       " 'we',\n",
       " 'well',\n",
       " 'wells',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'would',\n",
       " 'x',\n",
       " 'y',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'young',\n",
       " 'younger',\n",
       " 'youngest',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'z'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemma: base word\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Sample Stop words\n",
    "# from http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "# rstrip See Docs\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))\n",
    "\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +ve and -ve Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load the reviews\n",
    "positive_reviews = BeautifulSoup(open('D:\\Random ML Projects\\Simple Sentiment Analysis Logistic Model\\sorted_data_acl\\electronics/positive.review').read(),'lxml')\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('D:\\Random ML Projects\\Simple Sentiment Analysis Logistic Model\\sorted_data_acl\\electronics/negative.review').read(),'lxml')\n",
    "negative_reviews = negative_reviews.findAll('review_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are more positive reviews than negative reviews\n",
    "# so let's take a random sample so we have balanced classes\n",
    "np.random.shuffle(positive_reviews)\n",
    "positive_reviews = positive_reviews[:len(negative_reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " This Uniden phone/answering system has been trouble free since we bought it three months ago.  Here's a list of the other things about this phone that I like most:\n",
       " 1.  The corded handset base unit can be used to make and receive calls even when the electricity is off.  This, along with price, was the main reason I bought this phone system.  This feature is unusual for a cordless phone system.\n",
       " 2.  The controls on the answering machine are simple and intuitive enough so that you don't have to refer to the manual when you need to set the clock or change the outgoing recording.\n",
       " 3.  Also, the answering machine has operated flawlessly so far.\n",
       " 4.  The battery life of the cordless handset has been excellent between charges.  At least a week, sometimes more.\n",
       " 5.  Voice quality of the cordless handset and the corded base handset are very good.\n",
       " \n",
       " However, there is something about this phone system that I don't like.\n",
       " --The cordless handset has a pretty limited range.  I had to locate the base unit in a central location in my 2,300 square foot house to get the handset to work in all rooms.\n",
       " \n",
       " But overall I think the phone is a good buy, if you can live with the distance restrictions of the cordless handset\n",
       " </review_text>, <review_text>\n",
       " This card is the largest size that will allow clean video with FinePix cameras from 2004 or earlier.  The picture-to-picture lag time is minimal with this card and video is excellent. \n",
       " \n",
       " From Fuji Website - \"NOTE: for owners of FinePix cameras made before 2004, check notice below for the operating compatibility of older FinePix cameras with Type M and H.\n",
       " </review_text>, <review_text>\n",
       " I'm overly critical of sound quality. At home i have the Tritton surround sound headset running off optical connection. this doesnt' compare to that but the Tritton is $99 too. \n",
       " \n",
       " For the $ this is really nice. Sound, microphone and wire quality are all good. Controls are easy to use and the software is easy to use too. They're also fairly comfortable. Good headset for work\n",
       " </review_text>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*first let's just try to tokenize the text using nltk's tokenizer\n",
    "let's take the first review for example:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Uniden',\n",
       " 'phone/answering',\n",
       " 'system',\n",
       " 'has',\n",
       " 'been',\n",
       " 'trouble',\n",
       " 'free',\n",
       " 'since',\n",
       " 'we',\n",
       " 'bought',\n",
       " 'it',\n",
       " 'three',\n",
       " 'months',\n",
       " 'ago',\n",
       " '.',\n",
       " 'Here',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'list',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'things',\n",
       " 'about',\n",
       " 'this',\n",
       " 'phone',\n",
       " 'that',\n",
       " 'I',\n",
       " 'like',\n",
       " 'most',\n",
       " ':',\n",
       " '1',\n",
       " '.',\n",
       " 'The',\n",
       " 'corded',\n",
       " 'handset',\n",
       " 'base',\n",
       " 'unit',\n",
       " 'can',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'make',\n",
       " 'and',\n",
       " 'receive',\n",
       " 'calls',\n",
       " 'even',\n",
       " 'when',\n",
       " 'the',\n",
       " 'electricity',\n",
       " 'is',\n",
       " 'off',\n",
       " '.',\n",
       " 'This',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'price',\n",
       " ',',\n",
       " 'was',\n",
       " 'the',\n",
       " 'main',\n",
       " 'reason',\n",
       " 'I',\n",
       " 'bought',\n",
       " 'this',\n",
       " 'phone',\n",
       " 'system',\n",
       " '.',\n",
       " 'This',\n",
       " 'feature',\n",
       " 'is',\n",
       " 'unusual',\n",
       " 'for',\n",
       " 'a',\n",
       " 'cordless',\n",
       " 'phone',\n",
       " 'system',\n",
       " '.',\n",
       " '2',\n",
       " '.',\n",
       " 'The',\n",
       " 'controls',\n",
       " 'on',\n",
       " 'the',\n",
       " 'answering',\n",
       " 'machine',\n",
       " 'are',\n",
       " 'simple',\n",
       " 'and',\n",
       " 'intuitive',\n",
       " 'enough',\n",
       " 'so',\n",
       " 'that',\n",
       " 'you',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'to',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'the',\n",
       " 'manual',\n",
       " 'when',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'set',\n",
       " 'the',\n",
       " 'clock',\n",
       " 'or',\n",
       " 'change',\n",
       " 'the',\n",
       " 'outgoing',\n",
       " 'recording',\n",
       " '.',\n",
       " '3',\n",
       " '.',\n",
       " 'Also',\n",
       " ',',\n",
       " 'the',\n",
       " 'answering',\n",
       " 'machine',\n",
       " 'has',\n",
       " 'operated',\n",
       " 'flawlessly',\n",
       " 'so',\n",
       " 'far',\n",
       " '.',\n",
       " '4',\n",
       " '.',\n",
       " 'The',\n",
       " 'battery',\n",
       " 'life',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cordless',\n",
       " 'handset',\n",
       " 'has',\n",
       " 'been',\n",
       " 'excellent',\n",
       " 'between',\n",
       " 'charges',\n",
       " '.',\n",
       " 'At',\n",
       " 'least',\n",
       " 'a',\n",
       " 'week',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'more',\n",
       " '.',\n",
       " '5',\n",
       " '.',\n",
       " 'Voice',\n",
       " 'quality',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cordless',\n",
       " 'handset',\n",
       " 'and',\n",
       " 'the',\n",
       " 'corded',\n",
       " 'base',\n",
       " 'handset',\n",
       " 'are',\n",
       " 'very',\n",
       " 'good',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'there',\n",
       " 'is',\n",
       " 'something',\n",
       " 'about',\n",
       " 'this',\n",
       " 'phone',\n",
       " 'system',\n",
       " 'that',\n",
       " 'I',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'like',\n",
       " '.',\n",
       " '--',\n",
       " 'The',\n",
       " 'cordless',\n",
       " 'handset',\n",
       " 'has',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'limited',\n",
       " 'range',\n",
       " '.',\n",
       " 'I',\n",
       " 'had',\n",
       " 'to',\n",
       " 'locate',\n",
       " 'the',\n",
       " 'base',\n",
       " 'unit',\n",
       " 'in',\n",
       " 'a',\n",
       " 'central',\n",
       " 'location',\n",
       " 'in',\n",
       " 'my',\n",
       " '2,300',\n",
       " 'square',\n",
       " 'foot',\n",
       " 'house',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'handset',\n",
       " 'to',\n",
       " 'work',\n",
       " 'in',\n",
       " 'all',\n",
       " 'rooms',\n",
       " '.',\n",
       " 'But',\n",
       " 'overall',\n",
       " 'I',\n",
       " 'think',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'buy',\n",
       " ',',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'live',\n",
       " 'with',\n",
       " 'the',\n",
       " 'distance',\n",
       " 'restrictions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cordless',\n",
       " 'handset']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = positive_reviews[0]\n",
    "nltk.tokenize.word_tokenize(t.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice how it doesn't downcase, so It != it\n",
    "not only that, but do we really want to include the word \"it\" anyway?\n",
    "you can imagine it wouldn't be any more common in a positive review than a negative review\n",
    "so it might only add noise to our model.\n",
    "so let's create a function that does all this pre-processing for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word-to-index map\n",
    "so that we can create our word-frequency vectors later\n",
    "let's also save the tokenized versions so we don't have to tokenize again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ veindexmap:  7560\n",
      "After +ve: 7560\n",
      "1000\n",
      "-ve indexmap:  11082\n",
      "After -ve: 11082\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Reviews Tokenized\n",
    "\n",
    "# +ve \n",
    "\n",
    "for review in positive_reviews:\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "print('+ veindexmap: ',len(word_index_map))\n",
    "print('After +ve:',current_index)\n",
    "print(len(positive_tokenized))\n",
    "# -ve \n",
    "for review in negative_reviews:\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "\n",
    "print('-ve indexmap: ',len(word_index_map))\n",
    "print('After -ve:',current_index)\n",
    "print(len(negative_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11082\n"
     ]
    }
   ],
   "source": [
    "print(current_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's create our input matrices\n",
    "\n",
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # last element is for the label\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        #print(i)\n",
    "        x[i] += 1\n",
    "    x = x / x.sum() # normalize it before setting label\n",
    "    x[-1] = label\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "11082\n"
     ]
    }
   ],
   "source": [
    "# total tokens\n",
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "print(N)\n",
    "print(len(word_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((N, len(word_index_map) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate: 0.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.04040749,  0.0052488 ,  0.33425694, ..., -0.02437702,\n",
       "       -0.02437702, -0.01010531])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the data and create train/test splits\n",
    "# try it multiple times!\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]\n",
    "\n",
    "# last 100 rows will be test\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Classification rate:\", model.score(Xtest, Ytest))\n",
    "\n",
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha 0.590195505418\n",
      "month -0.824051177174\n",
      "unit -0.919491741945\n",
      "price 2.83978614139\n",
      "wa -1.8034481463\n",
      "feature 0.50771967563\n",
      "n't -2.11379150262\n",
      "excellent 1.44632167659\n",
      "week -0.786199047561\n",
      "quality 1.53000486545\n",
      "pretty 0.657576034538\n",
      "buy -0.921493043647\n",
      "video 0.57280657481\n",
      "time -0.645708033936\n",
      "sound 1.17261671991\n",
      "home 0.537151645027\n",
      "easy 1.85511908527\n",
      "comfortable 0.680849055742\n",
      "picture 0.658036564498\n",
      "look 0.616684030444\n",
      "little 0.957516284817\n",
      "bad -0.761206004103\n",
      "lot 0.792064055857\n",
      "fit 0.514990602141\n",
      "doe -1.27757172535\n",
      "maybe -0.515748189939\n",
      "try -0.679413341228\n",
      "poor -0.809874315774\n",
      "piece -0.519202889412\n",
      "fast 0.969309515197\n",
      "bit 0.682294511208\n",
      "cheap -0.514401572359\n",
      "'ve 0.763995303521\n",
      "item -0.976915258409\n",
      "company -0.557044456454\n",
      "perfect 1.09572442808\n",
      "highly 1.03688119928\n",
      "paper 0.585026481305\n",
      "using 0.759546336123\n",
      "minute -0.509269938493\n",
      "recommend 0.730217556076\n",
      "speaker 0.892461221779\n",
      "laptop 0.62819448549\n",
      "customer -0.72262255593\n",
      "happy 0.61533482338\n",
      "returning -0.580717015395\n",
      "hour -0.714652957748\n",
      "sent -0.511956929523\n",
      "called -0.519642532057\n",
      "love 1.14280268473\n",
      "cable 0.769483783939\n",
      "money -1.12871808275\n",
      "space 0.615778046427\n",
      "memory 1.08342853095\n",
      "tried -0.92672309505\n",
      "static -0.568553874188\n",
      "pro 0.510895264154\n",
      "value 0.560398748656\n",
      "support -0.964413609605\n",
      "warranty -0.600845505967\n",
      "stopped -0.608862753051\n",
      "return -1.26706963061\n",
      "returned -0.762411598735\n",
      "refund -0.700531864674\n",
      "waste -1.01179900296\n",
      "junk -0.555559195426\n",
      "terrible -0.554868116853\n"
     ]
    }
   ],
   "source": [
    "# let's look at the weights for each word\n",
    "# try it with different threshold values!\n",
    "\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "for word, index in (word_index_map).items():\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
